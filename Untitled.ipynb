{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How pyMentalModel works\n",
    "=============\n",
    "\n",
    "pyMentalModels relies on numpy, sympy and pyparsing\n",
    "\n",
    "The structre of the program looks like so:\n",
    "    - Parse expression using pyparsing\n",
    "    - Process it using sympy\n",
    "    - Build a mental model as np.n(2)darray \n",
    "    - Make some inference with regard to the mental model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mental Modal reasoner uses sympy at the moment to parse expressions.\n",
    "I make use of the function sympify that returns a logical object that has the nice method'* `atoms` that lists the individual atoms of an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_format in module pyMentalModels.modal_parser:\n",
      "\n",
      "parse_format(expression:str, rules:Dict[str, str])\n",
      "    Short function to both parse and format an expression and return a sympy object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyMentalModels.modal_parser import parse_format\n",
    "help(parse_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'&': 'And',\n",
       " '->': 'Implies',\n",
       " '<->': 'Equivalent',\n",
       " '<>': 'Possibly',\n",
       " '[]': 'Necessary',\n",
       " '^': 'Xor',\n",
       " '|': 'Or',\n",
       " '~': 'Not'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyMentalModels.operators import explicit_op, intuit_op\n",
    "explicit_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'&': 'And',\n",
       " '->': 'And',\n",
       " '<->': 'And',\n",
       " '<>': 'Possibly',\n",
       " '[]': 'Necessary',\n",
       " '^': 'Xor',\n",
       " '|': 'Or',\n",
       " '~': 'Not'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intuit_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a & b, {a, b}, (a, b))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_exp = parse_format(\"a -> b\", intuit_op)\n",
    "\n",
    "parsed_exp, parsed_exp.atoms(), parsed_exp.args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Implies(a, b)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_format(\"a -> b\", explicit_op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the Mental Models are constructed...\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMentalModels.numpy_reasoner import mental_model_builder, map_instance_to_operation, Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mental_model_builder in module pyMentalModels.numpy_reasoner:\n",
      "\n",
      "mental_model_builder(sympified_expr, mode=<Insight.INTUITIVE: 0>)\n",
      "    Builds a mental model representation of the logical expression.\n",
      "    \n",
      "    A Mental model is a mental representation of a logical or indeed any expression.\n",
      "    An example would be the expression:\n",
      "    \n",
      "        You have either the salad or the soup or the bread\n",
      "    \n",
      "    The mental model representation would then be:\n",
      "    \n",
      "                    Salad\n",
      "                            Soup\n",
      "                                    Bread\n",
      "    \n",
      "    `mental_model_builder` recursively builds models of the subexpressions of\n",
      "    the total expression, merges them and returns the overall mental model\n",
      "    representation of the expression\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sympified_expr: sympy BooleanFunction\n",
      "        An expression formatted and processed by the `sympy` python module\n",
      "        Attributes:\n",
      "            expression.atoms\n",
      "                Set of all the atoms in the logical expression\n",
      "            expression.args\n",
      "                Tuple of arguments the outermost logical operator takes\n",
      "    mode: Insight\n",
      "        Insight can be either Insight.INTUITIVE or Insight.FULL\n",
      "        The mental models differ accordingly:\n",
      "    \n",
      "            The sentence               The mental       The fully\n",
      "                                       models of its    explicit\n",
      "                                       possibilities    models\n",
      "            ==========================|==============|============\n",
      "            A And B                   |    A   B     |    A   B\n",
      "            --------------------------|--------------|------------\n",
      "            Neither A nor B           |   ~A  ~B     |   ~A  ~B\n",
      "            --------------------------|--------------|------------\n",
      "            A or else B, but not both |    A         |    A  ~B\n",
      "                                      |        B     |   ~A   B\n",
      "            --------------------------|--------------|------------\n",
      "            A or B or both            |    A         |    A  ~B\n",
      "                                      |        B     |   ~A   B\n",
      "                                      |    A   B     |    A   B\n",
      "            --------------------------|--------------|------------\n",
      "            If A then B               |    A   B     |    A   B\n",
      "                                      |     ...      |   ~A  ~B\n",
      "                                      |              |   ~A   B\n",
      "            --------------------------|--------------|------------\n",
      "            If and only if A then B   |    A   B     |    A   B\n",
      "                                      |     ...      |   ~A  ~B\n",
      "    \n",
      "    \n",
      "    -------\n",
      "    Mental model representation of logical expression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mental_model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mental_model_builder(sympified_expr, mode=Insight.INTUITIVE):\n",
    "    # Extract atoms from sympified expression\n",
    "    exp_atoms = sorted(sympified_expr.atoms(), key=str)\n",
    "\n",
    "    # map every atom to its corresponding index in the model\n",
    "    atom_index_mapping = {atom: i for i, atom in enumerate(exp_atoms)}\n",
    "\n",
    "    return mental_model(sympified_expr, map_instance_to_operation(sympified_expr)(sympified_expr, atom_index_mapping, exp_atoms), exp_atoms, atom_index_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function map_instance_to_operation in module pyMentalModels.numpy_reasoner:\n",
      "\n",
      "map_instance_to_operation(el)\n",
      "    maps every logical instance to its builder function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(map_instance_to_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_instance_to_operation(el):\n",
    "    \"maps every logical instance to its builder function.\"\n",
    "    maps = iter((\n",
    "        (Or, build_or),\n",
    "        (And, build_and),\n",
    "        (Xor, build_xor),\n",
    "        (Implies, build_implication),\n",
    "        (Equivalent, build_and),\n",
    "        (Not, build_not),\n",
    "        (Necessary, build_necessary),\n",
    "        (Possibly, build_possibly),\n",
    "        (Symbol, lambda *_: np.array([[POS_VAL]])),\n",
    "    ))\n",
    "    try:\n",
    "        return next(builder for type_, builder in maps if isinstance(el, type_))\n",
    "    except StopIteration:\n",
    "        raise ValueError(\"Not a valid operator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier exemplarisch die Funktion build_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and(exp, atom_index_mapping, exp_atoms):\n",
    "\n",
    "    assert(isinstance(exp, (And, Implies, Equivalent)))\n",
    "\n",
    "    and_args = exp.args\n",
    "\n",
    "    if all(isinstance(el, Symbol) for el in and_args):\n",
    "        and_model = np.zeros((1, len(exp_atoms)))\n",
    "        and_model[\n",
    "            :, list(map(lambda x: atom_index_mapping[x], and_args))\n",
    "        ] = POS_VAL\n",
    "        return and_model\n",
    "    else:\n",
    "        symbol_list = []\n",
    "        subexpression_list = []\n",
    "        for el in exp.args:\n",
    "            if isinstance(el, Symbol):\n",
    "                symbol_list.append(el)\n",
    "            else:\n",
    "                subexpression_list.append(el)\n",
    "        # generate submodels from subexpressions\n",
    "        modelized_subexpressions = [\n",
    "            map_instance_to_operation(subexpression)(subexpression, atom_index_mapping, exp_atoms)\n",
    "            for subexpression in subexpression_list\n",
    "        ]\n",
    "        # Create `and` model for the symbols\n",
    "        if symbol_list:\n",
    "            and_model = np.zeros((1, len(exp_atoms)))\n",
    "            and_model[\n",
    "                :, list(map(lambda x: atom_index_mapping[x], symbol_list))\n",
    "            ] = POS_VAL\n",
    "            modelized_subexpressions.append(and_model)\n",
    "\n",
    "        # merge the generated submodels to an overall model of `And`\n",
    "        merged_sub_models = _merge_models(*modelized_subexpressions, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "        if merged_sub_models.size:\n",
    "            return np.unique(merged_sub_models, axis=0)\n",
    "        else:\n",
    "            return merged_sub_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMentalModels.numpy_reasoner import _merge_models, _increasing_ones_first_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _merge_models in module pyMentalModels.numpy_reasoner:\n",
      "\n",
      "_merge_models(*sub_models, atom_index_mapping, exp_atoms, op)\n",
      "    Merges the different subexpressions together.\n",
      "    Implements merging for operator `And`, `Or`, `Xor`\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sub_models: List[np.ndarray]\n",
      "        List of arbitrary number of sub_models subexpressions to be merged together\n",
      "    \n",
      "    atom_index_mapping: Dict\n",
      "        Mapping of atom to its index in np.ndarray representation of a mental model\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    np.ndarray\n",
      "        Merged `submodels` as `merged_models`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(_merge_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_models(*sub_models, atom_index_mapping, exp_atoms, op):\n",
    "    \"\"\"\n",
    "    Merges the different subexpressions together.\n",
    "    Implements merging for operator `And`, `Or`, `Xor`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_models: List[np.ndarray]\n",
    "        List of arbitrary number of sub_models subexpressions to be merged together\n",
    "\n",
    "    atom_index_mapping: Dict\n",
    "        Mapping of atom to its index in np.ndarray representation of a mental model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Merged `submodels` as `merged_models`\n",
    "\n",
    "    \"\"\"\n",
    "    assert(len(sub_models)) >= 2\n",
    "\n",
    "    sub_models = tuple(np.atleast_2d(model) for model in sub_models)\n",
    "\n",
    "    if op == \"And\":\n",
    "        logging.debug(\"Arguments for `And` merge: \")\n",
    "        logging.debug(sub_models)\n",
    "        print(sub_models)\n",
    "\n",
    "        iter_models = iter(sub_models)\n",
    "        merged_models = next(iter_models)\n",
    "        for model in iter_models:\n",
    "            \"\"\"\n",
    "            pre-process every submodel so that the combinations are allowed\n",
    "                only compare relevant indices,\n",
    "             i.e. (A & B) | (B & C)\n",
    "                  1  1  0   0  1  1\n",
    "\n",
    "            \"\"\"\n",
    "            # Gather indices of atoms that are active in the models\n",
    "            merged_model_active_indices = {i for i, val in enumerate(merged_models.any(axis=0)) if val}\n",
    "            model_active_indices = {i for i, val in enumerate(model.any(axis=0)) if val}\n",
    "\n",
    "            # single out the overlapping atoms in both models (i.e. (A B) & (B C) -> B)\n",
    "            atom_indices_to_check = list(merged_model_active_indices & model_active_indices)\n",
    "            logging.debug(\"Atoms in both models: {}\".format(list(map(lambda x: exp_atoms[x], atom_indices_to_check))))\n",
    "\n",
    "            if atom_indices_to_check:  # if there are overlapping indices for both models\n",
    "                sub_models_merged_model = []\n",
    "\n",
    "                def same_val(val1, val2):\n",
    "                    return (val1 == POS_VAL and val2 == POS_VAL) \\\n",
    "                        or (val1 in (IMPL_NEG, EXPL_NEG) and val2 in (IMPL_NEG, EXPL_NEG))\n",
    "                for submodel in merged_models:\n",
    "                    allowed_models = []\n",
    "                    for sub_model_to_check in model:\n",
    "                        if all(same_val(*vals) for vals in zip(submodel[atom_indices_to_check], sub_model_to_check[atom_indices_to_check])):\n",
    "                            allowed_models.append(sub_model_to_check)\n",
    "                    logging.debug(\"Allowed models are: {}\".format(allowed_models))\n",
    "                    if not allowed_models:\n",
    "                        continue\n",
    "                    allowed_models = np.stack(allowed_models)\n",
    "                    reshaped_submodel = np.repeat(np.atleast_2d(submodel), len(allowed_models), axis=0)\n",
    "                    logging.debug(\"LENGTH ALLOWD: {}\".format(len(allowed_models)))\n",
    "                    logging.debug(\"Sub: {}\".format(submodel))\n",
    "                    logging.debug(\"reshaped: {}\".format(reshaped_submodel))\n",
    "                    logging.debug(\"{}\".format(allowed_models))\n",
    "                    logging.debug(\"Reshaped submodel: {}\".format(reshaped_submodel))\n",
    "                    submodel_added_with_allowed_models = reshaped_submodel + allowed_models\n",
    "                    # after adding values can either be 2, -2 , -3 or -4 for the indexes that are active in both models\n",
    "                    # for the other indices values are 0, -1, -2 or 1\n",
    "                    # for the active indices map 2, -2, -3 and -4 to 1, -1, -2\n",
    "                    submodel_added_with_allowed_models[:, atom_indices_to_check] //= 2\n",
    "                    logging.debug(\"added submodel with allowed model\", submodel_added_with_allowed_models)\n",
    "                    sub_models_merged_model.append(submodel_added_with_allowed_models)\n",
    "                    logging.debug(\"List of valid submodels until now:\", sub_models_merged_model)\n",
    "\n",
    "                # finished iterating through all submodels\n",
    "                # has collected all valid combinations of both the models\n",
    "                # if there are still no combinations of any submodel with the other model\n",
    "                # return the empty array\n",
    "                if sub_models_merged_model:\n",
    "                    iter_models = iter(sub_models_merged_model)\n",
    "                    merged_models = next(iter_models)\n",
    "                    for sub_model in iter_models:\n",
    "                        merged_models = np.vstack((merged_models, sub_model))\n",
    "                else:\n",
    "                    logging.info(\"AND yields the empty array\")\n",
    "                    return np.array([[]])\n",
    "            else:\n",
    "                reshaped_merged_models = np.repeat(merged_models, len(model), axis=0)\n",
    "                reshaped_model2 = np.tile(model, (len(merged_models), 1))\n",
    "                merged_models = reshaped_merged_models + reshaped_model2\n",
    "\n",
    "        logging.debug(\"Merged `AND`: \")\n",
    "        logging.debug(merged_models)\n",
    "        return merged_models\n",
    "\n",
    "    if op == \"Xor\":\n",
    "        \"\"\"\n",
    "        Takes complement of one model and the other model and adds them together\n",
    "\n",
    "        generate complement for each model\n",
    "              0  0  0\n",
    "              0  1  0  ...\n",
    "              1  0  0\n",
    "\n",
    "              combine for all models in merged_models\n",
    "              and check if models to be added are compatible with preexisting\n",
    "              merged models\n",
    "\n",
    "            i.e. Model1 & ~Model2\n",
    "                ~Model1 &  Model2\n",
    "        \"\"\"\n",
    "        logging.debug(sub_models)\n",
    "        negated_models = [\n",
    "            _complement_array_model(model, atom_index_mapping, exp_atoms)\n",
    "            for model in sub_models\n",
    "        ]\n",
    "        # for each model in sub_models add the model\n",
    "        # with the complements of all other submodels\n",
    "        pos_neg_combinations = [\n",
    "            _merge_models(\n",
    "                model,\n",
    "                *(neg_model for j, neg_model in enumerate(negated_models) if j != i),\n",
    "                atom_index_mapping=atom_index_mapping,\n",
    "                exp_atoms=exp_atoms, op=\"And\"\n",
    "            )\n",
    "            for i, model in enumerate(sub_models)\n",
    "        ]\n",
    "        iter_models = iter(pos_neg_combinations)\n",
    "        merged_models = next(iter_models)\n",
    "        for model in iter_models:\n",
    "            merged_models = np.vstack((merged_models, model))\n",
    "        return merged_models\n",
    "\n",
    "    if op == \"Or\":\n",
    "        # first xor everything\n",
    "        xor_models = _merge_models(*sub_models, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"Xor\")\n",
    "        merged_models = xor_models\n",
    "        # then piecewise and everything\n",
    "        list_of_piecewise_ands = [\n",
    "            _merge_models(*comb, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "            for comb in combinations(sub_models, 2)\n",
    "        ]\n",
    "        for el in list_of_piecewise_ands:\n",
    "            merged_models = np.vstack((merged_models, el))\n",
    "\n",
    "        # then total and everything\n",
    "        and_everything = _merge_models(*sub_models, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "\n",
    "        merged_models = np.vstack((merged_models, and_everything))\n",
    "\n",
    "        merged_models[merged_models > 0] = 1\n",
    "        merged_models[merged_models < 0] = -1\n",
    "        return merged_models\n",
    "\n",
    "    if op == \"implication\":\n",
    "        \"\"\" get 1 1\n",
    "                0 1\n",
    "                0 0 combination\"\"\"\n",
    "        antecedent, consequent = sub_models\n",
    "        complement_antecedent = _complement_array_model(antecedent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms)\n",
    "        logging.debug(\"complement_antecedent\")\n",
    "        logging.debug(complement_antecedent)\n",
    "        complement_consequent = _complement_array_model(consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms)\n",
    "\n",
    "        logging.debug(\"complement_consequent\")\n",
    "        logging.debug(complement_consequent)\n",
    "\n",
    "        list_of_combinations = []\n",
    "\n",
    "        # antecedent and conseqent together\n",
    "        antecedent_consequent = _merge_models(antecedent, consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "\n",
    "        if antecedent_consequent.size:\n",
    "            list_of_combinations.append(antecedent_consequent)\n",
    "\n",
    "        logging.debug(\"Combination 1 1\")\n",
    "        logging.debug(antecedent_consequent)\n",
    "\n",
    "        # complement of ante and consequent\n",
    "        comp_antecedent_consequent = _merge_models(complement_antecedent, consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "\n",
    "        if comp_antecedent_consequent.size:\n",
    "            list_of_combinations.append(comp_antecedent_consequent)\n",
    "\n",
    "        logging.debug(\"Combination 0 1\")\n",
    "        logging.debug(comp_antecedent_consequent)\n",
    "\n",
    "        # ante and complement of consequent\n",
    "        comp_antecedent_comp_consequent = _merge_models(complement_antecedent, complement_consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "\n",
    "        if comp_antecedent_comp_consequent.size:\n",
    "            list_of_combinations.append(comp_antecedent_comp_consequent)\n",
    "\n",
    "        logging.debug(\"Combination 0 0\")\n",
    "        logging.debug(comp_antecedent_comp_consequent)\n",
    "\n",
    "        # complement of ante and complement of consequent\n",
    "        merged_models = np.vstack(list_of_combinations)\n",
    "        logging.debug(\"Total merged `Implication` model: \")\n",
    "        logging.debug(merged_models)\n",
    "        return merged_models\n",
    "\n",
    "    if op == \"Equivalent\":\n",
    "        \"\"\" get 1 1\n",
    "                0 1\n",
    "                0 0 combination\"\"\"\n",
    "        antecedent, consequent = sub_models\n",
    "        complement_antecedent = _complement_array_model(antecedent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms)\n",
    "        logging.debug(\"complement_antecedent\")\n",
    "        logging.debug(complement_antecedent)\n",
    "        complement_consequent = _complement_array_model(consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms)\n",
    "\n",
    "        logging.debug(\"complement_consequent\")\n",
    "        logging.debug(complement_consequent)\n",
    "\n",
    "        merged_models = _merge_models(antecedent, consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "        logging.debug(\"Combination 1 1\")\n",
    "        logging.debug(merged_models)\n",
    "\n",
    "        comp_antecedent_comp_consequent = _merge_models(complement_antecedent, complement_consequent, atom_index_mapping=atom_index_mapping, exp_atoms=exp_atoms, op=\"And\")\n",
    "        logging.debug(\"Combination 0 0\")\n",
    "        logging.debug(comp_antecedent_comp_consequent)\n",
    "\n",
    "        merged_models = np.vstack((merged_models, comp_antecedent_comp_consequent))\n",
    "        logging.debug(\"Total merged `Implication` model: \")\n",
    "        logging.debug(merged_models)\n",
    "        return merged_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is then returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference\n",
    "=====\n",
    "\n",
    "Depending on the input of the inference task the function `infere()` will process the models differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMentalModels.infer import infer, InferenceTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class InferenceTask in module pyMentalModels.infer:\n",
      "\n",
      "class InferenceTask(enum.Enum)\n",
      " |  An enumeration.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      InferenceTask\n",
      " |      enum.Enum\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  FOLLOWS = <InferenceTask.FOLLOWS: 'what_follows?'>\n",
      " |  \n",
      " |  NECESSARY = <InferenceTask.NECESSARY: 'necessary?'>\n",
      " |  \n",
      " |  POSSIBLE = <InferenceTask.POSSIBLE: 'possible?'>\n",
      " |  \n",
      " |  PROBABILITY = <InferenceTask.PROBABILITY: 'probability?'>\n",
      " |  \n",
      " |  VERIFY = <InferenceTask.VERIFY: 'verify?'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from enum.Enum:\n",
      " |  \n",
      " |  name\n",
      " |      The name of the Enum member.\n",
      " |  \n",
      " |  value\n",
      " |      The value of the Enum member.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from enum.EnumMeta:\n",
      " |  \n",
      " |  __members__\n",
      " |      Returns a mapping of member name->value.\n",
      " |      \n",
      " |      This mapping lists all enum members, including aliases. Note that this\n",
      " |      is a read-only view of the internal mapping.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(InferenceTask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function infer in module pyMentalModels.infer:\n",
      "\n",
      "infer(models:List, task=None)\n",
      "    Parameters\n",
      "    ----------\n",
      "    models: List of mental_model NamedTuples with attributes:\n",
      "        Attributes:\n",
      "            expression: Logical expression that has been processed (Sympy.object)\n",
      "            model: The resulting mental model representation (np.ndarry)\n",
      "            atoms_model: list of atoms in the expression (list)\n",
      "            atom_index_mapping: mapping of atoms to their column in `model` (Dict)\n",
      "    task: InferenceTask\n",
      "            One of the InferenceTask.values:\n",
      "                1. what_follows?:\n",
      "                    Set task: Infer what follows from all premises\n",
      "                2. necessary?:\n",
      "                    Set task: Given all but last premises, infer if last premise necessarily follows\n",
      "                3. possible?:\n",
      "                    Set task: Given all but last premises, infer if last premise possibly follows\n",
      "                4. probability?:\n",
      "                    Set task: Given all but last premises, infer the probability of last premis\n",
      "                5. verify?:\n",
      "                    Set task: Given evidence last premise, verify all but last\n",
      "                6. Otherwise\n",
      "                    No task specified and so builds models of all the premises\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "        if \"infer\":\n",
      "            Infer a conclusion based on the premises\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
