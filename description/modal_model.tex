\documentclass{article}
\usepackage{hyperref}
\def\UrlBreaks{\do\/\do-}
\usepackage{mathtools}
%\usepackage[english]{babel}
\usepackage{xcolor}

\usepackage{pgf}
\usepackage{color}
\newcommand{\textred}[1]{{\color{red} #1}}
\newcommand{\bluetext}[1]{{\color{blue} #1}}
\newcommand{\textgreen}[1]{{\color{green} #1}}
\newcommand{\redtext}[1]{{\color{red} #1}}
\newcommand{\bluetext}[1]{{\color{blue} #1}}
\newcommand{\graytext}[1]{{\color{gray} #1}}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs,url}
\newtheorem{theorem}{Theorem}      %[chapter]
\newtheorem{proposition}[theorem]{Proposition}%[chapter]
\newtheorem{lemma}[theorem]{Lemma}%[chapter]
\newtheorem{corollary}[theorem]{Corollary}%[chapter]
\newtheorem{definition}[theorem]{Definition}%[chapter]
%\usepackage{wasysym}
%\usepackage{dsfont}
%\usepackage{mdwtools}
%\usepackage{multicol}
%\setlength{\columnsep}{5mm}

% fürs Einbinden von Graphiken
%\usepackage{graphicx}
%\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{syntax}
\usepackage{pgfplots}

\title{Technical Report: Implementing a Modal Mental Model Reasoner in Python and on the Web}
\author{M. Ragni \& M. Rocholl}
\begin{document}
\maketitle
\section{Introduction}
The goal is to implement a modal mReasoner\footnote{\url{http://mentalmodels.princeton.edu/models/mreasoner/}} for the Web. Let us first consider an example from sentential reasoning: 
There exists illusions in reasoning about propositional assertions \cite{Khemlani2009d}. Illusions are inferences where participants are convinced that the drawn conclusions are true, while they are wrong:
\begin{quote}
	\begin{tabular}{p{.1cm}p{.9\textwidth}}
		(1) & Consider, for instance, the following assertion: ``You have the bread, or else you have the soup or else the salad. Given the further premise: You have the bread.'' What follows? Can you have the soup too? What about the soup and the salad?
	\end{tabular}
\end{quote}

Please note that participants were instructed to interpret the or else as an exclusive or (XOR). Hence the problem can be reformulated as bread XOR soup XOR salad. But, only 17\% of the participants gave the correct answer that you can have all three. This answer is predicted by the underlying mental model representation. How do participants process this example? 

\subsection{System 1: Model generation}
Participants first interpret the first connective XOR as follows:

You have the bread or else you have the soup, \ldots

This leads to an iconic model of the form:
\begin{center}
\begin{tabular}{ll}
	Bread & \\
	& Soup \\
\end{tabular}
\end{center}
This depends on the interpretation of the sentence. This interpretation $I$ is (because of the connective or) a relation $R$ over propositional statements (i.e., atomic propositions with the connectives and ($\wedge$), or ($\vee$), not ($\neg$)) and a discrete twodimensional structure (we choose $\mathbb{N} \times \mathbb{N}$) and use for practical reasons in the implementation as data type a matrix or array. Hence, we define the relation $R$ inductively:
\begin{center}
	\begin{small}
\begin{tabular}{ll}\toprule
	Proposition & Mapping \\ \midrule
	A and B & $A^I = (x,y)$, $B^I = (x+i,y)$ with $x, y, i \in \mathbb{N}$ and $i > 0$\\
	A xor B & $A^I = (x,y)$, $B^I = (x+i,y-j)$ with $x, y, i \in \mathbb{N}$ and $i,j > 0$ \\
	if A, then B & $A^I = (x,y)$ and $B^I = (x+i,y)$ with $x, y, i \in \mathbb{N}$ and $i > 0$\\
	A or B & $A^I = \{(x,y), (x-k,y)\}$, $B^I = (x+i,y+j),(x-k,y+j)\}$\\
	&   with $x, y, i, j \in \mathbb{N}$ and $i,j,k > 0$\\ \bottomrule
\end{tabular}
\end{small}
\end{center}

A \emph{minimal mental model} is one that satisifies the constraints from the table with smallest $i, j, k$. 

\begin{definition}[Parsing principle]
The parsing and interpretation of a formula takes place in a small scope, i.e., each connective is interpreted successivly and the next proposition is then integrated. 
\end{definition}

hence the new information \emph{\ldots or else the salad} is processed and the mental model is updated:
\begin{center}
	\begin{tabular}{lll}
		Bread & & \\
		& Soup & \\
		& & Salad \\
	\end{tabular}
\end{center}

hence the mapping is $(1,1) = Bread^I$, $(2,2) = Soup^I$, $(3,3) = Salad^I$. A non-empty cell represents that the respective item is true. In Python the array is initialized with the package numpy\footnote{\url{https://stackoverflow.com/questions/6667201/how-to-define-two-dimensional-array-in-python}}. This concludes the model generation phase.

\subsection{System 1: Model inspection}
Given is Bread and the program checks for the computed model, if Bread and Soup is possible. As there is no row with Bread and Soup the program returns NO. The same holds for all three, the model returns again NO.

\subsection{System 2: Flesh out phase}
Each empty entry in the array is fleshed out. Hence, the program returns YES.
 
\section{Extension/Formalization for Reasoning with Modals}

\subsection{The model theory of epistemic possibilities}
\begin{enumerate}
	\item Models represent \bluetext{possibilities} {\footnotesize{(J-L \& Byrne, 1991)}} \smallskip 
	\item Compounds of \bluetext{alternatives} refer by default to
	exhaustive conjunctions of possibilities, e.g.:
	\emph{A or else B, but not both}\\
	has two mental models (system 1):
	\begin{center}
	\begin{tabular}{ll}
	 A & \\
	& B \\
	\end{tabular}
\end{center}
	{\footnotesize{ (J-L, Khemlani, \& Goodwin, 2015.)}} \\
	Fully explicit models (system 2) also represent
	what's impossible. \smallskip 
	\item A \bluetext{conjunction}, \textit{A and B}, makes a factual claim: 
	both propositions hold in all possibilities. \smallskip
	\item \bluetext{Parsimony:} \textit{possible that A and possible that B}  
	has a mental model of a single possibility: \\[+.2cm]
	\hspace{1cm} A \hspace{1cm} B
\end{enumerate}




	\subsubsection{Experiment 2}
	\begin{itemize}
		\item \bluetext{Parsimony unifies possibilities}, e.g.: \\
		\textit{Possibly, Tom is here and possibly Ann is here} \\ 
		has mental model of one possibility of who?s here:\\ 
		\hspace{1cm} Tom \hspace{1cm} Ann \\ 
		$\therefore$ \textit{Possibly, Tom is here and Ann is here. }\\ (Yes in model theory/ No in modal logics) \\
		\item Control problems, e.g., converse inference:
		\item \textit{Possibly, Tom is here and Ann is here.} \\
		$\therefore$ \textit{Possibly Tom is here and possibly Ann is here.} (Yes/Yes)
	\end{itemize}


\subsection{Parsing Grammar}

The parsing grammar for modal reasoning is specified in the Backus-Naur-Form:
\begin{grammar}
	 <atom> ::= <string\_without\_spaces\_and\_tabs>\\
	 <necessary> ::= [] \\
	<possibly> ::= "<>"\\
    <not> ::= "~"\\
    <and> ::= "&"\\
    <or> ::= "or"\\
    <xor> ::= "xor"\\
    <imply>::= "->"\\
    <biconditional>::= "<->"\\
    <operation> ::=  <atom> | <necessary> <operation> | <possibly>
    <operation> | <not> <operation> |
		   <operation><and><operation> | <operation><or><operation>
                   |  <operation> <xor> <operation> | <operation> <implies>
                   <operation> | <operation> <biconditional> <operation>\\
    <expr> ::= <operation> | <operation> <expr>
\end{grammar}

\subsection{The process model}
 Process model of the modal implementation:

\begin{enumerate}
    \item[Step 1] Expression is parsed by the parsing algorithm based on the         grammar introduced above.
    \item[Step 2] Convert the list representing the parsed expression into a
        string that can be interpreted by Pythons SymPy library.
    \item[Step 3] The function sympify from the sympy library in Python then processes
        the expression in a manner defined by the normal logical rules. The
        rules are here redefined to better represent the "human" understanding.
    \item[Step 4] The sympified expression is an object of the logical class
        that has the least depth.
        Using the attributes of the logical object, the atoms are cached within
        it as an attribute, we hence populate an array of the dimension $\mid Atoms \mid$.
        I.e., Xor(Bread, Butter, Milk) $\to 3 D$.
        Each Atom has one column and each row is one possibility.
        For each logical operator, different rules apply to the process of populating the model.
        Step 4 is repeated recursively for each operator in the expression.
    \item[Step5] The final matrix is then evaluated using bitmaps of the different rows and columns.
        Possible inferences are returned.
\end{enumerate}


The parsed expression:
\begin{grammar}
    <Expr> ::= "Bread xor Butter xor Salad"
\end{grammar}   
yields the array:
\begin{center}
    ['Bread', 'xor', 'Butter', 'xor' 'Salad']
\end{center}
After formatting: 
\begin{center}
Xor(Bread, Butter, Salad)
\end{center}
After passing the string to the sympify function:
\begin{center}
 Xor(Bread, Butter, Salad)\\
Object-type: Xor\\
$    Xor \to attributes$ := \{Bread, Butter, Salad\}\\
\end{center}

Repeat evaluation with the original expression substituting Xor by Or.

\subsection*{Flow chart representation of algorithm}
%\label{sub:flow_chart_representation_of_algorithm}


% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [ellipse, draw,fill=red!20, node distance=3cm,
    minimum height=3em, text width=4.5em, text badly centered]
    

\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (init) {input  expression};
    \node [cloud, right of=init] (system) {intuitive or full model};
    \node [block, below of=init] (parse) {Parse expression};
    \node [block, below of=parse] (format) {Format parsed expression};
    \node [block, below of=format] (evaluate) {Simplify expression};
    \node [block, below of=evaluate] (initialize) {Initialize or update array};
    \node [cloud, below of=system, node distance=2.5cm] (operators) {Definition of logical operators};
    \node [block, left of=evaluate, node distance=3cm] (update) {recursively evaluate next};
    \node [decision, below of=initialize] (decide) {maximum formula depth?};
    \node [block, below of=decide, node distance=3cm] (inference) {Make modal logical inference};
    % Draw edges
    \path [line] (init) -- (parse);
    \path [line] (parse) -- (format);
    \path [line] (format) -- (evaluate);
    \path [line] (evaluate) -- (initialize);
    \path [line] (initialize) -- (decide);
    \path [line] (decide) -| node [near start] {no} (update);
    \path [line] (update) |- (evaluate);
    \path [line] (decide) -- node {yes}(inference);
    \path [line,dashed] (system) -- (init);
    \path [line,dashed] (system) -- (operators);
    \path [line,dashed] (operators) |- (evaluate);
    \path [line,dashed] (operators) |- (initialize);
\end{tikzpicture}

\section{State \& Next steps}
\begin{itemize}
\item The parser already works
\item The next step is to model the possibility operator in the model
\end{itemize}

\bibliographystyle{apalike}
\bibliography{new5}
\end{document}
